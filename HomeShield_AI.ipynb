{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d76f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached pandas-2.3.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, python-dotenv, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/5 [pytz]\n",
      "   ---------------------------------------- 0/5 [pytz]\n",
      "   ---------------------------------------- 0/5 [pytz]\n",
      "   ---------------------------------------- 0/5 [pytz]\n",
      "   ---------------------------------------- 0/5 [pytz]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   -------- ------------------------------- 1/5 [tzdata]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   ------------------------ --------------- 3/5 [numpy]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   -------------------------------- ------- 4/5 [pandas]\n",
      "   ---------------------------------------- 5/5 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.2.6 pandas-2.3.1 python-dotenv-1.1.1 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1151f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure endpoint configured: True\n",
      "Policy directory exists: True\n",
      "Customer data exists: True\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, uuid, glob\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---- 1. Load Environment Variables ----\n",
    "# Point directly to your .env file (absolute path)\n",
    "env_path = Path(r\"C:\\Users\\kalva\\AI_Projects\\HomeShield_AI\") / \".env\"\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# ---- 2. Required Variables Check ----\n",
    "required_vars = [\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "    \"AZURE_OPENAI_API_KEY\", \n",
    "    \"PINECONE_API_KEY\"\n",
    "]\n",
    "\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing env vars: {missing}\")\n",
    "\n",
    "# ---- 3. Path Configuration ----\n",
    "POLICY_DIR = Path(r\"C:\\Users\\kalva\\AI_Projects\\HomeShield_AI\\policies_docs\")\n",
    "CUSTOMERS_CSV = Path(r\"C:\\Users\\kalva\\AI_Projects\\HomeShield_AI\\homeshield_sample_data\\customers.csv\")\n",
    "EVAL_PAIRS = Path(r\"C:\\Users\\kalva\\AI_Projects\\HomeShield_AI\\homeshield_sample_data\\evaluation_pairs.jsonl\")\n",
    "\n",
    "# ---- 4. Validation ----\n",
    "print(\"Azure endpoint configured:\", bool(os.getenv(\"AZURE_OPENAI_ENDPOINT\")))\n",
    "print(\"Policy directory exists:\", POLICY_DIR.exists())\n",
    "print(\"Customer data exists:\", CUSTOMERS_CSV.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242f4daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pinecone\n",
      "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
      "  Using cached pinecone_plugin_assistant-1.7.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Collecting urllib3>=1.26.0 (from pinecone)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting requests<3.0.0,>=2.32.3 (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone)\n",
      "  Using cached charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl.metadata (37 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 786.8/786.8 kB 4.8 MB/s eta 0:00:00\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "Using cached pinecone_plugin_assistant-1.7.0-py3-none-any.whl (239 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: urllib3, typing-inspection, tqdm, sniffio, pydantic-core, pinecone-plugin-interface, packaging, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, requests, pydantic, httpcore, anyio, pinecone-plugin-assistant, httpx, pinecone, openai\n",
      "\n",
      "   ----------------------------------------  0/22 [urllib3]\n",
      "   --- ------------------------------------  2/22 [tqdm]\n",
      "   ------- --------------------------------  4/22 [pydantic-core]\n",
      "  Attempting uninstall: packaging\n",
      "   ------- --------------------------------  4/22 [pydantic-core]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ------- --------------------------------  4/22 [pydantic-core]\n",
      "   ---------- -----------------------------  6/22 [packaging]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ---------- -----------------------------  6/22 [packaging]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ---------- -----------------------------  6/22 [packaging]\n",
      "   ---------- -----------------------------  6/22 [packaging]\n",
      "   -------------- -------------------------  8/22 [idna]\n",
      "   -------------------- ------------------- 11/22 [charset_normalizer]\n",
      "   ------------------------- -------------- 14/22 [requests]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   ----------------------------- ---------- 16/22 [httpcore]\n",
      "   ------------------------------ --------- 17/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [pinecone-plugin-assistant]\n",
      "   -------------------------------- ------- 18/22 [pinecone-plugin-assistant]\n",
      "   -------------------------------- ------- 18/22 [pinecone-plugin-assistant]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   ------------------------------------ --- 20/22 [pinecone]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   -------------------------------------- - 21/22 [openai]\n",
      "   ---------------------------------------- 22/22 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.10.0 certifi-2025.8.3 charset_normalizer-3.4.3 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.99.9 packaging-24.2 pinecone-7.3.0 pinecone-plugin-assistant-1.7.0 pinecone-plugin-interface-0.0.7 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ce16d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to existing Pinecone index: homeshield-policies\n",
      "\n",
      "Index Configuration:\n",
      "- Dimensions: 1536\n",
      "- Metric: cosine\n",
      "- Vector Count: 0\n",
      "- Embedding Model: text-embedding-3-small\n",
      "\n",
      "Index validation successful - ready for operations!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# ----- Secure Configuration -----\n",
    "def get_env_var(name, default=None):\n",
    "    \"\"\"Safely get environment variable with validation\"\"\"\n",
    "    value = os.environ.get(name, default)\n",
    "    if value is None and default is None:\n",
    "        raise ValueError(f\"Missing required environment variable: {name}\")\n",
    "    return value\n",
    "\n",
    "# Azure OpenAI Config\n",
    "AZURE_OPENAI_ENDPOINT = get_env_var(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = get_env_var(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VER = get_env_var(\"AZURE_OPENAI_API_VERSION\")\n",
    "EMBED_MODEL = get_env_var(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\") \n",
    "CHAT_MODEL = get_env_var(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "\n",
    "# Pinecone Config\n",
    "PC_API_KEY = get_env_var(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX = get_env_var(\"PINECONE_INDEX\")\n",
    "PINECONE_REGION = get_env_var(\"PINECONE_REGION\")\n",
    "\n",
    "# ----- Client Initialization -----\n",
    "# Azure OpenAI Client\n",
    "oai_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VER,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    ")\n",
    "\n",
    "# Pinecone Client\n",
    "pc = Pinecone(api_key=PC_API_KEY)\n",
    "\n",
    "# ----- Index Verification -----\n",
    "print(f\"Connecting to existing Pinecone index: {PINECONE_INDEX}\")\n",
    "index = pc.Index(PINECONE_INDEX)\n",
    "\n",
    "# Verify index configuration matches your expectations\n",
    "index_stats = index.describe_index_stats()\n",
    "print(\"\\nIndex Configuration:\")\n",
    "print(f\"- Dimensions: {index_stats.dimension}\")\n",
    "print(f\"- Metric: {index_stats.metric}\")\n",
    "print(f\"- Vector Count: {index_stats.total_vector_count}\")\n",
    "print(f\"- Embedding Model: {EMBED_MODEL}\")\n",
    "\n",
    "# Safety check for embedding dimension\n",
    "expected_dim = 1536  # text-embedding-3-small uses 1536 dimensions\n",
    "if index_stats.dimension != expected_dim:\n",
    "    print(f\"\\nWARNING: Index dimension ({index_stats.dimension}) doesn't match expected ({expected_dim})\")\n",
    "    print(\"You may need to recreate your index with the correct dimensions\")\n",
    "else:\n",
    "    print(\"\\nIndex validation successful - ready for operations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093dfaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-pinecone\n",
      "  Downloading langchain_pinecone-0.2.11-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.74 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-openai) (1.99.9)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.11.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Downloading langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.11.7)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2025.7.34-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: pinecone<8.0.0,>=6.0.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (7.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-pinecone) (2.2.6)\n",
      "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone)\n",
      "  Using cached langchain_tests-0.3.20-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pytest<9,>=7 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pytest_asyncio-0.26.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached syrupy-4.9.1-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting pytest-benchmark (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pytest_benchmark-5.1.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pytest-codspeed (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pytest_codspeed-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pytest-recording (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pytest_recording-0.13.4-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting vcrpy>=7.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached vcrpy-7.0.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.7.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.5.0)\n",
      "Collecting aiohttp>=3.9.0 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Using cached aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.4.6)\n",
      "Collecting iniconfig>=1 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.19.2)\n",
      "Collecting tomli>=1 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading multidict-6.6.4-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Downloading orjson-3.11.2-cp310-cp310-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai)\n",
      "  Downloading zstandard-0.24.0-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
      "Collecting wrapt (from vcrpy>=7.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting py-cpuinfo (from pytest-benchmark->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting cffi>=1.17.1 (from pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting rich>=13.8.1 (from pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pycparser (from cffi>=1.17.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.8.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.8.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
      "Downloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.11.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 884.2/884.2 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading langchain_pinecone-0.2.11-py3-none-any.whl (23 kB)\n",
      "Using cached langchain_tests-0.3.20-py3-none-any.whl (46 kB)\n",
      "Using cached aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Using cached pytest-8.4.1-py3-none-any.whl (365 kB)\n",
      "Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Using cached pytest_asyncio-0.26.0-py3-none-any.whl (19 kB)\n",
      "Using cached pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached syrupy-4.9.1-py3-none-any.whl (52 kB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl (452 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.4-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Using cached iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.14-py3-none-any.whl (373 kB)\n",
      "Downloading orjson-3.11.2-cp310-cp310-win_amd64.whl (119 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading regex-2025.7.34-cp310-cp310-win_amd64.whl (276 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached vcrpy-7.0.0-py2.py3-none-any.whl (42 kB)\n",
      "Downloading zstandard-0.24.0-cp310-cp310-win_amd64.whl (505 kB)\n",
      "Using cached pytest_benchmark-5.1.0-py3-none-any.whl (44 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached pytest_codspeed-4.0.0-py3-none-any.whl (107 kB)\n",
      "Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached pytest_recording-0.13.4-py3-none-any.whl (13 kB)\n",
      "Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Installing collected packages: py-cpuinfo, zstandard, wrapt, tomli, tenacity, regex, PyYAML, pycparser, propcache, pluggy, orjson, multidict, mdurl, jsonpointer, iniconfig, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, tiktoken, requests-toolbelt, pytest, markdown-it-py, jsonpatch, cffi, aiosignal, vcrpy, syrupy, rich, pytest-socket, pytest-benchmark, pytest-asyncio, aiohttp, pytest-recording, pytest-codspeed, langsmith, aiohttp-retry, langchain-core, langchain-tests, langchain-openai, langchain-pinecone\n",
      "\n",
      "   -- -------------------------------------  3/42 [tomli]\n",
      "   ---- -----------------------------------  5/42 [regex]\n",
      "   ------ ---------------------------------  7/42 [pycparser]\n",
      "   ------ ---------------------------------  7/42 [pycparser]\n",
      "   ----------- ---------------------------- 12/42 [mdurl]\n",
      "   --------------- ------------------------ 16/42 [attrs]\n",
      "   ----------------- ---------------------- 18/42 [aiohappyeyeballs]\n",
      "   -------------------- ------------------- 21/42 [requests-toolbelt]\n",
      "   -------------------- ------------------- 22/42 [pytest]\n",
      "   -------------------- ------------------- 22/42 [pytest]\n",
      "   -------------------- ------------------- 22/42 [pytest]\n",
      "   -------------------- ------------------- 22/42 [pytest]\n",
      "   --------------------- ------------------ 23/42 [markdown-it-py]\n",
      "   --------------------- ------------------ 23/42 [markdown-it-py]\n",
      "   ----------------------- ---------------- 25/42 [cffi]\n",
      "   ------------------------ --------------- 26/42 [aiosignal]\n",
      "   -------------------------- ------------- 28/42 [syrupy]\n",
      "   --------------------------- ------------ 29/42 [rich]\n",
      "   --------------------------- ------------ 29/42 [rich]\n",
      "   --------------------------- ------------ 29/42 [rich]\n",
      "   ----------------------------- ---------- 31/42 [pytest-benchmark]\n",
      "   ------------------------------- -------- 33/42 [aiohttp]\n",
      "   ------------------------------- -------- 33/42 [aiohttp]\n",
      "   ------------------------------- -------- 33/42 [aiohttp]\n",
      "   ---------------------------------- ----- 36/42 [langsmith]\n",
      "   ---------------------------------- ----- 36/42 [langsmith]\n",
      "   ------------------------------------ --- 38/42 [langchain-core]\n",
      "   ------------------------------------ --- 38/42 [langchain-core]\n",
      "   ------------------------------------ --- 38/42 [langchain-core]\n",
      "   ------------------------------------ --- 38/42 [langchain-core]\n",
      "   ------------------------------------ --- 38/42 [langchain-core]\n",
      "   ------------------------------------ --- 38/42 [langchain-core]\n",
      "   ------------------------------------- -- 39/42 [langchain-tests]\n",
      "   -------------------------------------- - 40/42 [langchain-openai]\n",
      "   ---------------------------------------- 42/42 [langchain-pinecone]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiohttp-retry-2.9.1 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 cffi-1.17.1 frozenlist-1.7.0 iniconfig-2.1.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.74 langchain-openai-0.3.30 langchain-pinecone-0.2.11 langchain-tests-0.3.20 langsmith-0.4.14 markdown-it-py-4.0.0 mdurl-0.1.2 multidict-6.6.4 orjson-3.11.2 pluggy-1.6.0 propcache-0.3.2 py-cpuinfo-9.0.0 pycparser-2.22 pytest-8.4.1 pytest-asyncio-0.26.0 pytest-benchmark-5.1.0 pytest-codspeed-4.0.0 pytest-recording-0.13.4 pytest-socket-0.7.0 regex-2025.7.34 requests-toolbelt-1.0.0 rich-14.1.0 syrupy-4.9.1 tenacity-9.1.2 tiktoken-0.11.0 tomli-2.2.1 vcrpy-7.0.0 wrapt-1.17.3 yarl-1.20.1 zstandard-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c537843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain ready → index: homeshield-policies | namespace: policies\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — LangChain + Azure embeddings + Pinecone VectorStore\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "# Azure LLM + Embeddings (deployment names come from your .env)\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"],\n",
    ")\n",
    "\n",
    "# Ensure Pinecone index exists with dim=1536 (Azure text-embedding-3-small)\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "INDEX_NAME   = os.environ[\"PINECONE_INDEX\"]\n",
    "REGION       = os.environ[\"PINECONE_REGION\"]\n",
    "DIM          = 1536  # Azure text-embedding-3-small\n",
    "\n",
    "if INDEX_NAME not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=REGION),\n",
    "    )\n",
    "\n",
    "# LangChain VectorStore handle (keep namespace stable)\n",
    "NAMESPACE = \"policies\"\n",
    "vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings, namespace=NAMESPACE)\n",
    "\n",
    "print(\"LangChain ready → index:\", INDEX_NAME, \"| namespace:\", NAMESPACE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29088dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (0.3.74)\n",
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pinecone-client\n",
      "  Using cached pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.26 (from langchain-community)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.43-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-community) (0.4.14)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langchain-core) (2.11.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community)\n",
      "  Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from pinecone-client) (2.9.0.post0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kalva\\anaconda3\\envs\\homeshield\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 13.2 MB/s eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, greenlet, async-timeout, typing-inspect, SQLAlchemy, pinecone-client, pydantic-settings, dataclasses-json, langchain-text-splitters, langchain, langchain-community\n",
      "\n",
      "   --------- ------------------------------  3/13 [greenlet]\n",
      "  Attempting uninstall: async-timeout\n",
      "   --------- ------------------------------  3/13 [greenlet]\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "   --------- ------------------------------  3/13 [greenlet]\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "   --------- ------------------------------  3/13 [greenlet]\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "   --------- ------------------------------  3/13 [greenlet]\n",
      "   --------------- ------------------------  5/13 [typing-inspect]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   ------------------ ---------------------  6/13 [SQLAlchemy]\n",
      "   --------------------------- ------------  9/13 [dataclasses-json]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   --------------------------------- ------ 11/13 [langchain]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ------------------------------------ --- 12/13 [langchain-community]\n",
      "   ---------------------------------------- 13/13 [langchain-community]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.43 async-timeout-4.0.3 dataclasses-json-0.6.7 greenlet-3.2.4 httpx-sse-0.4.1 langchain-0.3.27 langchain-community-0.3.27 langchain-text-splitters-0.3.9 marshmallow-3.26.1 mypy-extensions-1.1.0 pinecone-client-6.0.0 pydantic-settings-2.10.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run this in a Jupyter notebook cell\n",
    "%pip install langchain-community langchain-core langchain-text-splitters pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28a72d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TXT files: 300\n",
      "Chunks: 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting:   0%|          | 0/71 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:   1%|▏         | 1/71 [00:05<06:02,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 64/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:   3%|▎         | 2/71 [00:09<05:24,  4.71s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:   4%|▍         | 3/71 [00:13<05:10,  4.56s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:   6%|▌         | 4/71 [00:18<05:05,  4.55s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:   7%|▋         | 5/71 [00:22<04:55,  4.48s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:   8%|▊         | 6/71 [00:27<05:05,  4.70s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  10%|▉         | 7/71 [00:32<04:53,  4.58s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  11%|█▏        | 8/71 [00:36<04:47,  4.57s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  13%|█▎        | 9/71 [00:41<04:39,  4.51s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  14%|█▍        | 10/71 [00:45<04:33,  4.48s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  15%|█▌        | 11/71 [00:49<04:26,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 704/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  17%|█▋        | 12/71 [00:54<04:19,  4.40s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  18%|█▊        | 13/71 [00:58<04:15,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  20%|█▉        | 14/71 [01:03<04:11,  4.42s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  21%|██        | 15/71 [01:07<04:06,  4.40s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  23%|██▎       | 16/71 [01:11<04:03,  4.42s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  24%|██▍       | 17/71 [01:16<03:57,  4.40s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  25%|██▌       | 18/71 [01:20<03:51,  4.38s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  27%|██▋       | 19/71 [01:25<03:51,  4.46s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  28%|██▊       | 20/71 [01:29<03:45,  4.43s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  30%|██▉       | 21/71 [01:34<03:41,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1344/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  31%|███       | 22/71 [01:38<03:40,  4.49s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  32%|███▏      | 23/71 [01:43<03:36,  4.51s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  34%|███▍      | 24/71 [01:47<03:32,  4.52s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  35%|███▌      | 25/71 [01:52<03:26,  4.49s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  37%|███▋      | 26/71 [01:56<03:21,  4.47s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  38%|███▊      | 27/71 [02:01<03:15,  4.45s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  39%|███▉      | 28/71 [02:05<03:11,  4.46s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  41%|████      | 29/71 [02:09<03:05,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  42%|████▏     | 30/71 [02:14<02:59,  4.38s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  44%|████▎     | 31/71 [02:18<02:55,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1984/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  45%|████▌     | 32/71 [02:22<02:50,  4.38s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  46%|████▋     | 33/71 [02:27<02:46,  4.38s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  48%|████▊     | 34/71 [02:31<02:42,  4.39s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  49%|████▉     | 35/71 [02:36<02:39,  4.44s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  51%|█████     | 36/71 [02:40<02:34,  4.40s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  52%|█████▏    | 37/71 [02:45<02:30,  4.42s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  54%|█████▎    | 38/71 [02:49<02:25,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  55%|█████▍    | 39/71 [02:53<02:20,  4.39s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  56%|█████▋    | 40/71 [02:58<02:16,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  58%|█████▊    | 41/71 [03:02<02:11,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2624/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  59%|█████▉    | 42/71 [03:07<02:09,  4.45s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  61%|██████    | 43/71 [03:11<02:04,  4.44s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  62%|██████▏   | 44/71 [03:16<01:59,  4.44s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  63%|██████▎   | 45/71 [03:20<01:57,  4.52s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  65%|██████▍   | 46/71 [03:25<01:51,  4.46s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  66%|██████▌   | 47/71 [03:29<01:47,  4.49s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  68%|██████▊   | 48/71 [03:33<01:42,  4.46s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  69%|██████▉   | 49/71 [03:38<01:38,  4.48s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  70%|███████   | 50/71 [03:42<01:33,  4.46s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  72%|███████▏  | 51/71 [03:47<01:28,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 3264/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  73%|███████▎  | 52/71 [03:51<01:23,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  75%|███████▍  | 53/71 [03:56<01:19,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  76%|███████▌  | 54/71 [04:00<01:14,  4.37s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  77%|███████▋  | 55/71 [04:04<01:10,  4.38s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  79%|███████▉  | 56/71 [04:09<01:05,  4.37s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  80%|████████  | 57/71 [04:13<01:01,  4.38s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  82%|████████▏ | 58/71 [04:17<00:57,  4.39s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  83%|████████▎ | 59/71 [04:22<00:53,  4.42s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  85%|████████▍ | 60/71 [04:26<00:48,  4.41s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  86%|████████▌ | 61/71 [04:31<00:44,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 3904/4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  87%|████████▋ | 62/71 [04:35<00:39,  4.43s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  89%|████████▊ | 63/71 [04:40<00:35,  4.45s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  90%|█████████ | 64/71 [04:44<00:31,  4.46s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  92%|█████████▏| 65/71 [04:49<00:27,  4.55s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  93%|█████████▎| 66/71 [04:53<00:22,  4.54s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  94%|█████████▍| 67/71 [04:58<00:18,  4.52s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  96%|█████████▌| 68/71 [05:02<00:13,  4.48s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  97%|█████████▋| 69/71 [05:07<00:09,  4.52s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting:  99%|█████████▊| 70/71 [05:11<00:04,  4.48s/it]INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "Upserting: 100%|██████████| 71/71 [05:15<00:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 4500/4500\n",
      "✅ Completed upsert to Pinecone index='homeshield-policies', namespace='policies'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Adapted “simple strategy” for our project (TXT + Azure + metadata + namespace)\n",
    "# with namespace wipe + 'text' metadata for LangChain compatibility\n",
    "\n",
    "import os, time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# --- Load env if needed (keeps your existing .env setup) ---\n",
    "# load_dotenv(Path(r\"C:\\Users\\kalva\\AI_Projects\\HomeShield_AI\") / \".env\")\n",
    "\n",
    "# --- 1) Load TXT policies ---\n",
    "raw_docs = []\n",
    "for p in POLICY_DIR.glob(\"*.txt\"):\n",
    "    raw_docs.extend(TextLoader(str(p), encoding=\"utf-8\").load())\n",
    "print(\"Loaded TXT files:\", len(raw_docs))\n",
    "\n",
    "# --- 2) Chunk ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=120, add_start_index=True)\n",
    "chunks = splitter.split_documents(raw_docs)\n",
    "print(\"Chunks:\", len(chunks))\n",
    "\n",
    "# --- 3) Attach metadata from filename: LHG_<Plan>_<STATE>_<YEAR>.txt ---\n",
    "def parse_meta_from_filename(path_str: str):\n",
    "    stem = Path(path_str).stem\n",
    "    parts = stem.split(\"_\")\n",
    "    if len(parts) >= 4 and parts[0] == \"LHG\":\n",
    "        _, plan, state, year = parts[:4]\n",
    "        try:\n",
    "            return {\"plan\": plan, \"state\": state, \"effective_year\": int(year)}\n",
    "        except:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "for i, d in enumerate(chunks):\n",
    "    src = d.metadata.get(\"source\", \"\")\n",
    "    d.metadata.update(parse_meta_from_filename(src))\n",
    "    d.metadata.setdefault(\"source\", Path(src).name or \"unknown.txt\")\n",
    "    d.metadata.setdefault(\"page\", (i // 5) + 1)\n",
    "    d.metadata.setdefault(\"section\", \"policy\")\n",
    "    d.metadata.setdefault(\"chunk_id\", f\"{d.metadata['source']}-{i:04d}\")\n",
    "\n",
    "# --- 4) Embeddings (Azure, 1536-dim) ---\n",
    "emb = AzureOpenAIEmbeddings(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"],\n",
    ")\n",
    "\n",
    "# --- 5) Pinecone client & index handle ---\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "\n",
    "# --- 6) Upsert with throttling (avoid 429s) & include 'text' in metadata ---\n",
    "BATCH = 64\n",
    "BASE_SLEEP = 3.0\n",
    "MAX_RETRIES = 6\n",
    "\n",
    "def embed_texts(texts):\n",
    "    # LangChain embeddings returns list of vectors\n",
    "    return emb.embed_documents(texts)\n",
    "\n",
    "def upsert_batch(batch, start_id):\n",
    "    texts = [d.page_content for d in batch]\n",
    "    vecs = embed_texts(texts)\n",
    "    vectors = []\n",
    "    for j, d in enumerate(batch):\n",
    "        vectors.append({\n",
    "            \"id\": f\"hs-{start_id + j:08d}\",\n",
    "            \"values\": vecs[j],\n",
    "            \"metadata\": {\n",
    "                **d.metadata,\n",
    "                \"text\": d.page_content,   # <-- critical: store text so LangChain can rebuild Documents\n",
    "            }\n",
    "        })\n",
    "    index.upsert(vectors=vectors, namespace=NAMESPACE)\n",
    "\n",
    "def add_batch_with_backoff(batch, start_id):\n",
    "    delay = BASE_SLEEP\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            upsert_batch(batch, start_id)\n",
    "            return\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            is_429 = (\"429\" in msg) or (\"Too Many Requests\" in msg) or (\"rate\" in msg.lower())\n",
    "            if not is_429 or attempt == MAX_RETRIES:\n",
    "                print(f\"[ERROR] Upsert failed (attempt {attempt}): {e}\")\n",
    "                raise\n",
    "            # exponential backoff with cap\n",
    "            sleep_for = min(delay * (1.8 ** (attempt - 1)), 30.0)\n",
    "            print(f\"[WARN] 429 rate limit; retrying in {sleep_for:.1f}s (attempt {attempt}/{MAX_RETRIES})\")\n",
    "            time.sleep(sleep_for)\n",
    "\n",
    "total = len(chunks)\n",
    "for i in tqdm(range(0, total, BATCH), desc=\"Upserting\"):\n",
    "    batch = chunks[i:i + BATCH]\n",
    "    add_batch_with_backoff(batch, start_id=i)\n",
    "    time.sleep(BASE_SLEEP)  # steady pacing\n",
    "    if (i // BATCH) % 10 == 0:\n",
    "        print(f\"Progress: {min(i + BATCH, total)}/{total}\")\n",
    "\n",
    "print(f\"✅ Completed upsert to Pinecone index='{INDEX_NAME}', namespace='{NAMESPACE}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448215b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore ready: homeshield-policies | ns: policies\n"
     ]
    }
   ],
   "source": [
    "# Bind LangChain to the same Pinecone index/namespace you just upserted into\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=emb,           # <-- reuse your AzureOpenAIEmbeddings instance\n",
    "    namespace=NAMESPACE      # \"policies\"\n",
    ")\n",
    "print(\"VectorStore ready:\", INDEX_NAME, \"| ns:\", NAMESPACE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e11b2bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.10.18\n",
      "langchain: 0.3.27\n",
      "langchain-openai: 0.3.30\n",
      "langchain-community: 0.3.27\n",
      "langchain-pinecone: 0.2.11\n",
      "pinecone-client: 6.0.0\n",
      "openai: 1.99.9\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib.metadata as md\n",
    "\n",
    "def v(pkg):\n",
    "    try:\n",
    "        return md.version(pkg)\n",
    "    except md.PackageNotFoundError:\n",
    "        return \"not installed\"\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"langchain:\", v(\"langchain\"))\n",
    "print(\"langchain-openai:\", v(\"langchain-openai\"))\n",
    "print(\"langchain-community:\", v(\"langchain-community\"))\n",
    "print(\"langchain-pinecone:\", v(\"langchain-pinecone\"))\n",
    "print(\"pinecone-client:\", v(\"pinecone-client\"))\n",
    "print(\"openai:\", v(\"openai\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73c959f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR hits: 8\n",
      "{'chunk_id': 'C:\\\\Users\\\\kalva\\\\AI_Projects\\\\HomeShield_AI\\\\policies_docs\\\\LHG_Gold_PA_2025.txt-1126', 'effective_year': 2025.0, 'page': 226.0, 'plan': 'Gold', 'section': 'policy', 'source': 'C:\\\\Users\\\\kalva\\\\AI_Projects\\\\HomeShield_AI\\\\policies_docs\\\\LHG_Gold_PA_2025.txt', 'start_index': 478.0, 'state': 'PA'} SECTION – HVAC\n",
      "- Compressor is covered for mechanical and electrical failures under the Gold plan, subject to exclusions listed below. Pre-existing conditions a\n"
     ]
    }
   ],
   "source": [
    "# 100% safe MMR using VectorStore API directly (no compressors involved)\n",
    "\n",
    "def retrieve_mmr(question: str, plan: str, state: str, year: int, k: int = 8, fetch_k: int = 24, lambda_mult: float = 0.5):\n",
    "    \"\"\"\n",
    "    Uses vectorstore.max_marginal_relevance_search to get diverse chunks.\n",
    "    Applies strict metadata filter so we only search the correct policy set.\n",
    "    \"\"\"\n",
    "    return vectorstore.max_marginal_relevance_search(\n",
    "        question,\n",
    "        k=k,\n",
    "        fetch_k=fetch_k,\n",
    "        lambda_mult=lambda_mult,\n",
    "        filter={\"plan\": plan, \"state\": state, \"effective_year\": year},\n",
    "    )\n",
    "\n",
    "def format_context(docs):\n",
    "    lines = []\n",
    "    for i, d in enumerate(docs):\n",
    "        src  = d.metadata.get(\"source\", \"\")\n",
    "        page = d.metadata.get(\"page\", \"\")\n",
    "        lines.append(f\"[{i}] {src} p.{page}\\n{d.page_content}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(lines)\n",
    "\n",
    "# smoke test\n",
    "_test = retrieve_mmr(\"HVAC compressor coverage\", \"Gold\", \"PA\", 2025)\n",
    "print(\"MMR hits:\", len(_test))\n",
    "print(_test[0].metadata, _test[0].page_content[:160])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "717f441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://homeshield.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits: 8\n",
      "{'chunk_id': 'C:\\\\Users\\\\kalva\\\\AI_Projects\\\\HomeShield_AI\\\\policies_docs\\\\LHG_Gold_PA_2025.txt-1126', 'effective_year': 2025.0, 'page': 226.0, 'plan': 'Gold', 'section': 'policy', 'source': 'C:\\\\Users\\\\kalva\\\\AI_Projects\\\\HomeShield_AI\\\\policies_docs\\\\LHG_Gold_PA_2025.txt', 'start_index': 478.0, 'state': 'PA'} \n",
      " SECTION – HVAC\n",
      "- Compressor is covered for mechanical and electrical failures under the Gold plan, subject to exclusions listed below. Pre-existing conditions and improper installation are excluded. Wear items (e.g., filters, belts) are excluded unless otherwise stated.\n",
      "- Evaporator Coil is covered for mechanical and electrical failures under the Gold plan, subject to exclusions listed below. Pre-existing conditions and improper installation are excluded. Wear items (e.g., filters, belts) are ex\n"
     ]
    }
   ],
   "source": [
    "docs = vectorstore.max_marginal_relevance_search(\n",
    "    \"HVAC compressor coverage\",\n",
    "    k=8, fetch_k=50, lambda_mult=0.5,\n",
    "    filter={\"plan\": \"Gold\", \"state\": \"PA\", \"effective_year\": 2025},\n",
    ")\n",
    "print(\"hits:\", len(docs))\n",
    "if docs:\n",
    "    print(docs[0].metadata, \"\\n\", docs[0].page_content[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homeshield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
